{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15f6c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries to look at the data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7af76a",
   "metadata": {},
   "source": [
    "## EDA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509cfe0",
   "metadata": {},
   "source": [
    "1. We do not need new fields, these fields are sufficient. But we might add more to compare different major cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca45f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the display settings so that we can see all of the data\n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "134d0731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the csv into a dataframe using pandas\n",
    "crime_df = pd.read_csv('../data/crimedata2.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d4d0ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2215 entries, 0 to 2214\n",
      "Columns: 147 entries, Êcommunityname to nonViolPerPop\n",
      "dtypes: float64(75), int64(29), object(43)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "crime_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82c55ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 147)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the number of rows and columns in the dataframe\n",
    "crime_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954f86a",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e390b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2215"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crime_df[crime_df.isna()==True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758b3c75",
   "metadata": {},
   "source": [
    "#### Question Mark Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70fa3202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(44592)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of '?' in the DataFrame\n",
    "question_mark_count = crime_df.apply(lambda row: row.astype(str).str.count('\\?')).sum().sum()\n",
    "question_mark_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0afd603",
   "metadata": {},
   "source": [
    "2. There is about 2215 missing values, and there are 44592 values where there are \"?\" values that are not interpretted as missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893c38c",
   "metadata": {},
   "source": [
    "## Features list\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b01dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_features  = [\"population\"]\n",
    "crime_features       = [ \"autoTheft\", \"autoTheftPerPop\", \"larcenies\", \"larcPerPop\", \"burglaries\", \"burglPerPop\", \"robberies\", \"robbbPerPop\"]\n",
    "money_features       = [\"medIncome\", \"RentMedian\", \"MedRent\"]\n",
    "race_features        = [\"racepctblack\", \"racePctWhite\", \"racePctAsian\", \"racePctHisp\"]\n",
    "age_features         = [\"agePct12t21\", \"agePct12t29\", \"agePct16t24\", \"agePct65up\"]\n",
    "categorical_features = ['Êcommunityname', 'state', 'countyCode', 'communityCode']\n",
    "qm_columns = [\n",
    "    'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps', 'LemasSwFTFieldPerPop', \n",
    "    'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic', 'PolicPerPop', \n",
    "    'RacialMatchCommPol', 'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', \n",
    "    'PctPolicAsian', 'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', \n",
    "    'PolicAveOTWorked', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr', \n",
    "    'LemasGangUnitDeploy', \"PolicBudgPerPop\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbb6b030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Êcommunityname</th>\n",
       "      <th>state</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>population</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>robberies</th>\n",
       "      <th>robbbPerPop</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>RentMedian</th>\n",
       "      <th>MedRent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BerkeleyHeightstownship</td>\n",
       "      <td>NJ</td>\n",
       "      <td>39</td>\n",
       "      <td>5320</td>\n",
       "      <td>11980</td>\n",
       "      <td>16</td>\n",
       "      <td>131.26</td>\n",
       "      <td>138</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>14</td>\n",
       "      <td>114.85</td>\n",
       "      <td>1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>75122</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marpletownship</td>\n",
       "      <td>PA</td>\n",
       "      <td>45</td>\n",
       "      <td>47616</td>\n",
       "      <td>23123</td>\n",
       "      <td>26</td>\n",
       "      <td>110.55</td>\n",
       "      <td>376</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>57</td>\n",
       "      <td>242.37</td>\n",
       "      <td>5</td>\n",
       "      <td>21.26</td>\n",
       "      <td>47917</td>\n",
       "      <td>560</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tigardcity</td>\n",
       "      <td>OR</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>29344</td>\n",
       "      <td>136</td>\n",
       "      <td>376.3</td>\n",
       "      <td>1797</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>274</td>\n",
       "      <td>758.14</td>\n",
       "      <td>56</td>\n",
       "      <td>154.95</td>\n",
       "      <td>35669</td>\n",
       "      <td>428</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gloversvillecity</td>\n",
       "      <td>NY</td>\n",
       "      <td>35</td>\n",
       "      <td>29443</td>\n",
       "      <td>16656</td>\n",
       "      <td>47</td>\n",
       "      <td>271.93</td>\n",
       "      <td>716</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>225</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>10</td>\n",
       "      <td>57.86</td>\n",
       "      <td>20580</td>\n",
       "      <td>250</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bemidjicity</td>\n",
       "      <td>MN</td>\n",
       "      <td>7</td>\n",
       "      <td>5068</td>\n",
       "      <td>11245</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91</td>\n",
       "      <td>728.93</td>\n",
       "      <td>4</td>\n",
       "      <td>32.04</td>\n",
       "      <td>17390</td>\n",
       "      <td>283</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Êcommunityname state countyCode communityCode  population autoTheft autoTheftPerPop larcenies larcPerPop burglaries burglPerPop robberies robbbPerPop  medIncome  RentMedian  MedRent\n",
       "0  BerkeleyHeightstownship    NJ         39          5320       11980        16          131.26       138    1132.08         14      114.85         1         8.2      75122        1001     1001\n",
       "1           Marpletownship    PA         45         47616       23123        26          110.55       376    1598.78         57      242.37         5       21.26      47917         560      627\n",
       "2               Tigardcity    OR          ?             ?       29344       136           376.3      1797    4972.19        274      758.14        56      154.95      35669         428      484\n",
       "3         Gloversvillecity    NY         35         29443       16656        47          271.93       716    4142.56        225     1301.78        10       57.86      20580         250      333\n",
       "4              Bemidjicity    MN          7          5068       11245        91          728.93      1060    8490.87         91      728.93         4       32.04      17390         283      332"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_df_new = crime_df[categorical_features + population_features + crime_features + money_features]\n",
    "crime_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a95daa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def correlation(dataframe: pd.DataFrame, chunk_size: int = 15, output_folder: str = \"../images/correlation\"):\n",
    "#     # Ensure the output directory exists\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "#     dataframe = dataframe.select_dtypes(include=\"number\")\n",
    "#     # Compute the correlation matrix\n",
    "#     corr_matrix = dataframe.corr()\n",
    "#     rows, cols = corr_matrix.shape\n",
    "#     chunk_number = 1\n",
    "\n",
    "#     # Loop over the correlation matrix in chunks\n",
    "#     for i in range(0, rows, chunk_size):\n",
    "#         for j in range(0, cols, chunk_size):\n",
    "#             # Select a chunk using iloc\n",
    "#             corr_chunk = corr_matrix.iloc[i:i+chunk_size, j:j+chunk_size]\n",
    "\n",
    "#             # Plot the current chunk as a heatmap\n",
    "#             plt.figure(figsize=(10, 8))\n",
    "#             sns.heatmap(corr_chunk, annot=True, cmap=\"coolwarm\", linewidths=.5, fmt=\".2f\")\n",
    "#             plt.title(f\"Correlation Matrix Chunk {chunk_number}\")\n",
    "\n",
    "#             # Save the heatmap to the specified folder\n",
    "#             output_path = os.path.join(output_folder, f\"correlation_chunk_{chunk_number}.png\")\n",
    "#             plt.savefig(output_path)\n",
    "#             plt.close()  # Close the figure to avoid displaying it in the notebook or memory overflow\n",
    "\n",
    "#             # Increment the chunk number\n",
    "#             chunk_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eea1b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to filter correlations higher than 0.70 or lower than -0.70, without taking absolute value\n",
    "# def filter_high_low_correlations(dataframe: pd.DataFrame, threshold: float = 0.70):\n",
    "#     dataframe = dataframe.select_dtypes(include=\"number\")\n",
    "\n",
    "#     # Compute the correlation matrix\n",
    "#     corr_matrix = dataframe.corr()  # Keep the actual correlation values\n",
    "\n",
    "#     # Filter the matrix to keep only values > 0.70 or < -0.70, excluding the 1.0 self-correlations\n",
    "#     filtered_corr = corr_matrix[((corr_matrix > threshold) | (corr_matrix < -threshold)) & (corr_matrix != 1.0)].stack().reset_index()\n",
    "\n",
    "#     # Rename columns for clarity\n",
    "#     filtered_corr.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
    "\n",
    "#     # Drop duplicate pairs (since correlation is symmetric)\n",
    "#     filtered_corr = filtered_corr.drop_duplicates(subset=['Correlation'])\n",
    "\n",
    "#     return filtered_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5602a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply the function to get high and low correlations\n",
    "# high_low_correlations = filter_high_low_correlations(crime_df)\n",
    "\n",
    "# # Display or use the result\n",
    "# print(high_low_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1407f94",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21b0ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlierChecker(data: pd.DataFrame, column: str):\n",
    "    iqr = data[column].quantile(0.75) - data[column].quantile(0.25)\n",
    "    upper_outliers = data[data[column] > data[column].quantile(0.75) + 1.5 * iqr]\n",
    "    lower_outliers = data[data[column] < data[column].quantile(0.25) - 1.5 * iqr]\n",
    "    return upper_outliers, lower_outliers\n",
    "\n",
    "def outlierSummary(data: pd.DataFrame, column: str):\n",
    "    upper, lower = outlierChecker(data, column)\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Upper Outliers: {len(upper)}\")\n",
    "    print(f\"Lower Outliers: {len(lower)}\")\n",
    "    print(f\"Normalized Upper Outliers: {len(upper)/data.shape[0]}\")\n",
    "    print(f\"Normalized Lower Outliers: {len(lower)/data.shape[0]}\")\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "def outlierSummary2(data: pd.DataFrame, column: str):\n",
    "    upper, lower = outlierChecker(data, column)\n",
    "    print(f\"Column: {column} has {len(upper)+len(lower)} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2750a9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: fold has 0 outliers\n",
      "Column: population has 219 outliers\n",
      "Column: householdsize has 93 outliers\n",
      "Column: racepctblack has 252 outliers\n",
      "Column: racePctWhite has 88 outliers\n",
      "Column: racePctAsian has 240 outliers\n",
      "Column: racePctHisp has 268 outliers\n",
      "Column: agePct12t21 has 153 outliers\n",
      "Column: agePct12t29 has 151 outliers\n",
      "Column: agePct16t24 has 206 outliers\n",
      "Column: agePct65up has 38 outliers\n",
      "Column: numbUrban has 165 outliers\n",
      "Column: pctUrban has 0 outliers\n",
      "Column: medIncome has 43 outliers\n",
      "Column: pctWWage has 25 outliers\n",
      "Column: pctWFarmSelf has 117 outliers\n",
      "Column: pctWInvInc has 2 outliers\n",
      "Column: pctWSocSec has 19 outliers\n",
      "Column: pctWPubAsst has 76 outliers\n",
      "Column: pctWRetire has 34 outliers\n",
      "Column: medFamInc has 63 outliers\n",
      "Column: perCapInc has 111 outliers\n",
      "Column: whitePerCap has 119 outliers\n",
      "Column: blackPerCap has 72 outliers\n",
      "Column: indianPerCap has 133 outliers\n",
      "Column: AsianPerCap has 116 outliers\n",
      "Column: HispPerCap has 85 outliers\n",
      "Column: NumUnderPov has 235 outliers\n",
      "Column: PctPopUnderPov has 37 outliers\n",
      "Column: PctLess9thGrade has 92 outliers\n",
      "Column: PctNotHSGrad has 27 outliers\n",
      "Column: PctBSorMore has 97 outliers\n",
      "Column: PctUnemployed has 65 outliers\n",
      "Column: PctEmploy has 13 outliers\n",
      "Column: PctEmplManu has 23 outliers\n",
      "Column: PctEmplProfServ has 79 outliers\n",
      "Column: PctOccupManu has 27 outliers\n",
      "Column: PctOccupMgmtProf has 80 outliers\n",
      "Column: MalePctDivorce has 8 outliers\n",
      "Column: MalePctNevMarr has 122 outliers\n",
      "Column: FemalePctDiv has 2 outliers\n",
      "Column: TotalPctDiv has 1 outliers\n",
      "Column: PersPerFam has 127 outliers\n",
      "Column: PctFam2Par has 36 outliers\n",
      "Column: PctKids2Par has 31 outliers\n",
      "Column: PctYoungKids2Par has 36 outliers\n",
      "Column: PctTeen2Par has 58 outliers\n",
      "Column: PctWorkMomYoungKids has 17 outliers\n",
      "Column: PctWorkMom has 34 outliers\n",
      "Column: NumKidsBornNeverMar has 275 outliers\n",
      "Column: PctKidsBornNeverMar has 177 outliers\n",
      "Column: NumImmig has 276 outliers\n",
      "Column: PctImmigRecent has 82 outliers\n",
      "Column: PctImmigRec5 has 51 outliers\n",
      "Column: PctImmigRec8 has 37 outliers\n",
      "Column: PctImmigRec10 has 6 outliers\n",
      "Column: PctRecentImmig has 226 outliers\n",
      "Column: PctRecImmig5 has 225 outliers\n",
      "Column: PctRecImmig8 has 228 outliers\n",
      "Column: PctRecImmig10 has 222 outliers\n",
      "Column: PctSpeakEnglOnly has 176 outliers\n",
      "Column: PctNotSpeakEnglWell has 265 outliers\n",
      "Column: PctLargHouseFam has 188 outliers\n",
      "Column: PctLargHouseOccup has 180 outliers\n",
      "Column: PersPerOccupHous has 72 outliers\n",
      "Column: PersPerOwnOccHous has 68 outliers\n",
      "Column: PersPerRentOccHous has 106 outliers\n",
      "Column: PctPersOwnOccup has 11 outliers\n",
      "Column: PctPersDenseHous has 178 outliers\n",
      "Column: PctHousLess3BR has 67 outliers\n",
      "Column: MedNumBR has 0 outliers\n",
      "Column: HousVacant has 251 outliers\n",
      "Column: PctHousOccup has 86 outliers\n",
      "Column: PctHousOwnOcc has 17 outliers\n",
      "Column: PctVacantBoarded has 165 outliers\n",
      "Column: PctVacMore6Mos has 12 outliers\n",
      "Column: MedYrHousBuilt has 0 outliers\n",
      "Column: PctHousNoPhone has 34 outliers\n",
      "Column: PctWOFullPlumb has 115 outliers\n",
      "Column: OwnOccLowQuart has 71 outliers\n",
      "Column: OwnOccMedVal has 89 outliers\n",
      "Column: OwnOccHiQuart has 115 outliers\n",
      "Column: OwnOccQrange has 179 outliers\n",
      "Column: RentLowQ has 19 outliers\n",
      "Column: RentMedian has 27 outliers\n",
      "Column: RentHighQ has 0 outliers\n",
      "Column: RentQrange has 96 outliers\n",
      "Column: MedRent has 26 outliers\n",
      "Column: MedRentPctHousInc has 62 outliers\n",
      "Column: MedOwnCostPctInc has 4 outliers\n",
      "Column: MedOwnCostPctIncNoMtg has 64 outliers\n",
      "Column: NumInShelters has 361 outliers\n",
      "Column: NumStreet has 417 outliers\n",
      "Column: PctForeignBorn has 179 outliers\n",
      "Column: PctBornSameState has 8 outliers\n",
      "Column: PctSameHouse85 has 22 outliers\n",
      "Column: PctSameCity85 has 73 outliers\n",
      "Column: PctSameState85 has 96 outliers\n",
      "Column: LandArea has 157 outliers\n",
      "Column: PopDens has 156 outliers\n",
      "Column: PctUsePubTrans has 228 outliers\n",
      "Column: LemasPctOfficDrugUn has 333 outliers\n",
      "Column: murders has 261 outliers\n",
      "Column: murdPerPop has 137 outliers\n"
     ]
    }
   ],
   "source": [
    "for col in crime_df.select_dtypes(include=[\"number\"]).columns.tolist():\n",
    "    outlierSummary2(data=crime_df, column=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bfc33",
   "metadata": {},
   "source": [
    "4. If we calculate the outliers with IQR method, then we see outliers in almost every column to take note of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b881b7",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "481f8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that we don't want to make numeric and creating a new df\n",
    "columns_to_drop = ['Êcommunityname', 'state', 'countyCode', 'communityCode']\n",
    "numeric_crime_df = crime_df.drop(columns=columns_to_drop)\n",
    "numeric_crime_df = numeric_crime_df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f7d2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a correlation matrix and save the correlation matrix to a CSV to check all columns\n",
    "correlation_matrix = numeric_crime_df.corr()\n",
    "correlation_matrix.to_csv('../data/correlation_matrix.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d054d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold so that we only get the results for features we would want to use\n",
    "threshold = 0.7\n",
    "\n",
    "high_correlation = correlation_matrix[(correlation_matrix > threshold) | (correlation_matrix < -threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d33379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are focused on autoTheft so we are going to only grab the columns of interest\n",
    "interest_columns = ['autoTheft', 'autoTheftPerPop']\n",
    "interest_correlation = correlation_matrix[interest_columns].sort_values(by='autoTheft', ascending=False)\n",
    "\n",
    "# print(interest_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "402153c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot a heatmap of the autoTheft correlation matrix\n",
    "# plt.figure(figsize=(20, 18))\n",
    "# sns.heatmap(interest_correlation, cmap='coolwarm', annot=False, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ff35c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoTheft        1.000000\n",
      "NumUnderPov      0.983919\n",
      "population       0.980754\n",
      "numbUrban        0.979503\n",
      "robberies        0.971612\n",
      "                   ...   \n",
      "PctTeen2Par     -0.167564\n",
      "PctFam2Par      -0.172405\n",
      "PctPolicWhite   -0.175015\n",
      "PctKids2Par     -0.177880\n",
      "racePctWhite    -0.206655\n",
      "Name: autoTheft, Length: 143, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Correlation of each feature with 'autoTheft'\n",
    "target_corr = correlation_matrix['autoTheft'].sort_values(ascending=False)\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b7e8ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlations for 'autoTheft' and 'autoTheftPerPop'\n",
    "autoTheft_corr = correlation_matrix['autoTheft'].drop('autoTheft')  # Drop self-correlation\n",
    "autoTheftPerPop_corr = correlation_matrix['autoTheftPerPop'].drop('autoTheftPerPop')  # Drop self-correlation\n",
    "\n",
    "# Sort and take the top 6\n",
    "top_autoTheft_corr = autoTheft_corr.abs().sort_values(ascending=False).head(6)\n",
    "top_autoTheftPerPop_corr = autoTheftPerPop_corr.abs().sort_values(ascending=False).head(6)\n",
    "\n",
    "# Create a df using the results\n",
    "top_correlations = pd.DataFrame({\n",
    "    'autoTheft': top_autoTheft_corr,\n",
    "    'autoTheftPerPop': top_autoTheftPerPop_corr\n",
    "})\n",
    "\n",
    "# Display the result\n",
    "# print(top_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80552669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NumUnderPov', 'ViolentCrimesPerPop', 'burglPerPop', 'burglaries', 'murdPerPop', 'murders', 'nonViolPerPop', 'numbUrban', 'population', 'racePctWhite', 'robbbPerPop', 'robberies'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose the df\n",
    "transposed_df = top_correlations.T\n",
    "\n",
    "transposed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b35346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a df with the original data but only with the columns of interest\n",
    "# featured_data = crime_df[['Êcommunityname', 'state', 'countyCode', \n",
    "#                           'communityCode','NumUnderPov', 'ViolentCrimesPerPop',\n",
    "#                           'burglPerPop', 'burglaries', 'murdPerPop', 'murders', \n",
    "#                           'nonViolPerPop', 'numbUrban', 'population', 'racePctWhite', \n",
    "#                           'robbbPerPop', 'robberies', 'autoTheft','autoTheftPerPop']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e36778",
   "metadata": {},
   "source": [
    "- Only categorical columns are geographic locations, so we can use them but I don't think it will help that much when creating a model.\n",
    "- There are a lot of numerical columns (some are shown as Object types). We might do binning depending on the distribution of a feature, if there is highly skewed variables, or for categorical representation like age range or area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8cb2ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our target variables will be autoTheft and autoTheftPerPop\n",
      "Our predictor variables will be the different races per capita, race pecentages, median income, maybe murders since it has a moderately positive correlation \n",
      "with auto theft, age, unemployed, employed, number in shelters, etc.\n",
      "Note: We might remove some features or replace them if we have different or new hyptheses, but we will definitely use race, median income, unemployed as demographic features. \n",
      "Crime features that we might use are larcenies, burglaries, and robberies. \n",
      "These crime features might be more useful as predictor variables but our goal to see the probablity of a auto theft happening depending on the value of these crime features.\n",
      "We can use some stereo types as our hypothesis and see what the outcome is to see if our hypothesis/stereotypes are actually true.\n"
     ]
    }
   ],
   "source": [
    "print(\"Our target variables will be autoTheft and autoTheftPerPop\")\n",
    "print(\"Our predictor variables will be the different races per capita, race pecentages, median income, maybe murders since it has a moderately positive correlation \\nwith auto theft, age, unemployed, employed, number in shelters, etc.\")\n",
    "print(\"Note: We might remove some features or replace them if we have different or new hyptheses, but we will definitely use race, median income, unemployed as demographic features. \\nCrime features that we might use are larcenies, burglaries, and robberies. \\nThese crime features might be more useful as predictor variables but our goal to see the probablity of a auto theft happening depending on the value of these crime features.\")\n",
    "print(\"We can use some stereo types as our hypothesis and see what the outcome is to see if our hypothesis/stereotypes are actually true.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
